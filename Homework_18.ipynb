{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is a neural network? What are the general steps required to build a neural network? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network is machine learning made up of at least three layers: the input layer, a hidden layer, and the output layer.  A neural network containing more than one hidden layer is said to be performing \"deep learning\".  The neural network takes the values from the input layer, and applies specified weights to them, and then calculates the results of their interactions with each other.  This calculation of weights and interactions happens at each layer until you reach the output layer, which is actually the prediction.\n",
    "The general steps to build a neural network are to:\n",
    "1. Specify the model setup, such as Sequential.\n",
    "2. Build each layer of the model, beginning with the input layer.  This will specify dense/sparse, number of nodes, activation type (typically 'relu'), and input shape.\n",
    "3. Hidden layers will each contain all of the specifications of the first layer except for input shape as their input will be the layer preceding.\n",
    "4. Build the output layer with dense/sparse, number of final answers you are looking for (one if regression, two if binary classification, variable depending on the data if classification other than binary)\n",
    "5. Compile the model.  Here you specify optimizer, loss function and metric for evaluating performance.\n",
    "6. Fit the model using at least predictions and target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generally, how do you check the performance of a neural network? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the performance of your model using validation scores. You can run epochs using optimization methods to determine the point at which you minimize your loss function.  The performance of your model at that point is maximized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a neural network using keras to predict the outcome of either of these datasets: \n",
    "### Cardiac Arrhythmia: https://archive.ics.uci.edu/ml/datasets/Arrhythmia \n",
    "### Abalone age: https://archive.ics.uci.edu/ml/datasets/Abalone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4177, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "\n",
    "ab_df=pd.read_csv('abalone.data',delimiter=',',header=None)\n",
    "ab_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_df.columns=['sex', 'length', 'diameter', 'height', 'whole_weight', 'shucked_weight', 'viscera_weight', 'shell_weight', 'rings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=ab_df[['sex', 'length', 'diameter', 'height', 'whole_weight', 'rings']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values, so moving on to reviewing/removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length          0.1650\n",
      "diameter        0.1300\n",
      "height          0.0500\n",
      "whole_weight    0.7115\n",
      "rings           3.0000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4081, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_rem_df=df.copy()\n",
    "# IQR\n",
    "Q1 = outlier_rem_df.quantile(0.25)\n",
    "Q3 = outlier_rem_df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)\n",
    "mod_df_out = outlier_rem_df[~((outlier_rem_df < (Q1 - 2.5 * IQR)) |(outlier_rem_df > (Q3 + 2.5 * IQR))).any(axis=1)]\n",
    "mod_df_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15,  7,  9, 10,  8, 16, 14, 11, 12, 18, 13,  5,  4,  6, 17,  1,  3,\n",
       "        2], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_df_out['rings'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding sex column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>rings</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_I</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4081 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  rings  sex_F  sex_I  sex_M\n",
       "0      0.455     0.365   0.095        0.5140     15      0      0      1\n",
       "1      0.350     0.265   0.090        0.2255      7      0      0      1\n",
       "2      0.530     0.420   0.135        0.6770      9      1      0      0\n",
       "3      0.440     0.365   0.125        0.5160     10      0      0      1\n",
       "4      0.330     0.255   0.080        0.2050      7      0      1      0\n",
       "...      ...       ...     ...           ...    ...    ...    ...    ...\n",
       "4172   0.565     0.450   0.165        0.8870     11      1      0      0\n",
       "4173   0.590     0.440   0.135        0.9660     10      0      0      1\n",
       "4174   0.600     0.475   0.205        1.1760      9      0      0      1\n",
       "4175   0.625     0.485   0.150        1.0945     10      1      0      0\n",
       "4176   0.710     0.555   0.195        1.9485     12      0      0      1\n",
       "\n",
       "[4081 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aba_df=pd.get_dummies(mod_df_out)\n",
    "aba_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will standardize values in model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4.441, Test: 4.610\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot\n",
    "\n",
    "X= aba_df.drop('rings', axis=1)\n",
    "y= aba_df['rings']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X_train, y_train)\n",
    "\n",
    "# define model\n",
    "n_cols = X_train.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu',input_shape=input_shape))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01, momentum=0.9))\n",
    "# fit model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)\n",
    "# evaluate the model\n",
    "train_mse = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# plot loss during training\n",
    "pyplot.title('Loss / Mean Squared Error')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write another algorithm to predict the same result using either KNN or logistical regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is:  0.21297429620563035\n",
      "Mean squared error is:  6.965728274173807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "X= aba_df.drop('rings', axis=1)\n",
    "y= aba_df['rings']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "#Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "y_predicted = knn.predict(X_test)\n",
    "print('Accuracy score is: ', knn.score(X_test, y_test))\n",
    "print('Mean squared error is: ', mse(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a neural network using pytorch to predict the same result as question 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "X= aba_df.drop('rings', axis=1)\n",
    "y= aba_df['rings']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "# #Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8417,  0.8321, -0.4758,  ..., -0.6766, -0.6998,  1.3414],\n",
      "        [ 1.1299,  1.1818,  1.9778,  ..., -0.6766,  1.4290, -0.7455],\n",
      "        [ 0.7182,  0.5323,  0.5573,  ..., -0.6766, -0.6998,  1.3414],\n",
      "        ...,\n",
      "        [-1.2167, -1.2664, -1.2506,  ..., -0.6766,  1.4290, -0.7455],\n",
      "        [ 1.5827,  1.1318,  1.0739,  ..., -0.6766, -0.6998,  1.3414],\n",
      "        [-0.5580, -0.3171, -0.3466,  ..., -0.6766, -0.6998,  1.3414]])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self, input_features=7, hidden1=50, hidden2=50, out_features =1):\n",
    "        super().__init__()\n",
    "        self.layer_1_connection = nn.Linear(input_features, hidden1)\n",
    "        self.layer_2_connection = nn.Linear(hidden1, hidden2)\n",
    "        self.out = nn.Linear(hidden2, out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer_1_connection(x))\n",
    "        x = F.relu(self.layer_2_connection(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model = ANN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "y_test = y_test.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1 with loss: 7.7665696144104\n",
      "Epoch number: 21 with loss: 7.76612663269043\n",
      "Epoch number: 41 with loss: 7.766013145446777\n",
      "Epoch number: 61 with loss: 7.766005516052246\n",
      "Epoch number: 81 with loss: 7.7660040855407715\n",
      "Epoch number: 101 with loss: 7.7660040855407715\n",
      "Epoch number: 121 with loss: 7.766005516052246\n",
      "Epoch number: 141 with loss: 7.769236087799072\n",
      "Epoch number: 161 with loss: 7.768919944763184\n",
      "Epoch number: 181 with loss: 7.767259120941162\n",
      "Epoch number: 201 with loss: 7.766138553619385\n",
      "Epoch number: 221 with loss: 7.766025066375732\n",
      "Epoch number: 241 with loss: 7.766005039215088\n",
      "Epoch number: 261 with loss: 7.766005039215088\n",
      "Epoch number: 281 with loss: 7.7660040855407715\n",
      "Epoch number: 301 with loss: 7.7661542892456055\n",
      "Epoch number: 321 with loss: 7.766026020050049\n",
      "Epoch number: 341 with loss: 7.766158103942871\n",
      "Epoch number: 361 with loss: 7.7686686515808105\n",
      "Epoch number: 381 with loss: 7.7667236328125\n",
      "Epoch number: 401 with loss: 7.766978740692139\n",
      "Epoch number: 421 with loss: 7.766167163848877\n",
      "Epoch number: 441 with loss: 7.766025066375732\n",
      "Epoch number: 461 with loss: 7.7660040855407715\n",
      "Epoch number: 481 with loss: 7.7660040855407715\n",
      "Epoch number: 501 with loss: 7.766003608703613\n",
      "Epoch number: 521 with loss: 7.766003608703613\n",
      "Epoch number: 541 with loss: 7.7660040855407715\n",
      "Epoch number: 561 with loss: 7.766003608703613\n",
      "Epoch number: 581 with loss: 7.766015529632568\n",
      "Epoch number: 601 with loss: 7.796019554138184\n",
      "Epoch number: 621 with loss: 7.771376132965088\n",
      "Epoch number: 641 with loss: 7.766611576080322\n",
      "Epoch number: 661 with loss: 7.766090393066406\n",
      "Epoch number: 681 with loss: 7.766012668609619\n",
      "Epoch number: 701 with loss: 7.766005039215088\n",
      "Epoch number: 721 with loss: 7.7660040855407715\n",
      "Epoch number: 741 with loss: 7.7660040855407715\n",
      "Epoch number: 761 with loss: 7.766003608703613\n",
      "Epoch number: 781 with loss: 7.766003608703613\n",
      "Epoch number: 801 with loss: 7.767289161682129\n",
      "Epoch number: 821 with loss: 7.7660651206970215\n",
      "Epoch number: 841 with loss: 7.766053199768066\n",
      "Epoch number: 861 with loss: 7.766024589538574\n",
      "Epoch number: 881 with loss: 7.767446041107178\n",
      "Epoch number: 901 with loss: 7.773784637451172\n",
      "Epoch number: 921 with loss: 7.76675271987915\n",
      "Epoch number: 941 with loss: 7.766023635864258\n",
      "Epoch number: 961 with loss: 7.766007900238037\n",
      "Epoch number: 981 with loss: 7.7660040855407715\n",
      "Epoch number: 1001 with loss: 7.766005039215088\n",
      "Epoch number: 1021 with loss: 7.766003608703613\n",
      "Epoch number: 1041 with loss: 7.766005516052246\n",
      "Epoch number: 1061 with loss: 7.774715423583984\n",
      "Epoch number: 1081 with loss: 7.772241115570068\n",
      "Epoch number: 1101 with loss: 7.766367435455322\n",
      "Epoch number: 1121 with loss: 7.7661356925964355\n",
      "Epoch number: 1141 with loss: 7.766014099121094\n",
      "Epoch number: 1161 with loss: 7.7660064697265625\n",
      "Epoch number: 1181 with loss: 7.7660040855407715\n",
      "Epoch number: 1201 with loss: 7.766003608703613\n",
      "Epoch number: 1221 with loss: 7.766003608703613\n",
      "Epoch number: 1241 with loss: 7.766003608703613\n",
      "Epoch number: 1261 with loss: 7.766016006469727\n",
      "Epoch number: 1281 with loss: 7.769372940063477\n",
      "Epoch number: 1301 with loss: 7.769168376922607\n",
      "Epoch number: 1321 with loss: 7.766122341156006\n",
      "Epoch number: 1341 with loss: 7.7661004066467285\n",
      "Epoch number: 1361 with loss: 7.766012668609619\n",
      "Epoch number: 1381 with loss: 7.767097473144531\n",
      "Epoch number: 1401 with loss: 7.772815227508545\n",
      "Epoch number: 1421 with loss: 7.766258239746094\n",
      "Epoch number: 1441 with loss: 7.7660322189331055\n",
      "Epoch number: 1461 with loss: 7.766005516052246\n",
      "Epoch number: 1481 with loss: 7.766007423400879\n",
      "Epoch number: 1501 with loss: 7.766005039215088\n",
      "Epoch number: 1521 with loss: 7.766040802001953\n",
      "Epoch number: 1541 with loss: 7.796660900115967\n",
      "Epoch number: 1561 with loss: 7.766411781311035\n",
      "Epoch number: 1581 with loss: 7.76603889465332\n",
      "Epoch number: 1601 with loss: 7.766040802001953\n",
      "Epoch number: 1621 with loss: 7.7660040855407715\n",
      "Epoch number: 1641 with loss: 7.766003608703613\n",
      "Epoch number: 1661 with loss: 7.766003608703613\n",
      "Epoch number: 1681 with loss: 7.766003608703613\n",
      "Epoch number: 1701 with loss: 7.7660064697265625\n",
      "Epoch number: 1721 with loss: 7.770839214324951\n",
      "Epoch number: 1741 with loss: 7.777014255523682\n",
      "Epoch number: 1761 with loss: 7.7681803703308105\n",
      "Epoch number: 1781 with loss: 7.766083240509033\n",
      "Epoch number: 1801 with loss: 7.766007900238037\n",
      "Epoch number: 1821 with loss: 7.766007423400879\n",
      "Epoch number: 1841 with loss: 7.7660040855407715\n",
      "Epoch number: 1861 with loss: 7.766003608703613\n",
      "Epoch number: 1881 with loss: 7.766003608703613\n",
      "Epoch number: 1901 with loss: 7.766003608703613\n",
      "Epoch number: 1921 with loss: 7.766002655029297\n",
      "Epoch number: 1941 with loss: 7.766002655029297\n",
      "Epoch number: 1961 with loss: 7.7660040855407715\n",
      "Epoch number: 1981 with loss: 7.839751243591309\n"
     ]
    }
   ],
   "source": [
    "final_loss = []\n",
    "n_epochs = 2000\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = model.forward(X_train)\n",
    "    loss = loss_function(y_pred.float(), y_train.float())\n",
    "    final_loss.append(loss)\n",
    "    \n",
    "    if epoch % 20 == 1:\n",
    "        print(f'Epoch number: {epoch} with loss: {loss.item()}')\n",
    "    \n",
    "    optimizer.zero_grad() #zero the gradient before running backwards propagation\n",
    "    loss.backward() #for backward propagation \n",
    "    optimizer.step() #performs one optimization step each epoch\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compare the performance of the neural networks to the other model you created. Which performed better? Why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural networks performed better.  I believe this is because of the built in methods for optimization of feature weights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
